{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import ast\n",
    "import os\n",
    "import utils\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "import numpy as np\n",
    "\n",
    "DIRPATH_DATA = \"Data\"\n",
    "DIRPATH_EXTRACTED_FEATURES = \"extracted_features\"\n",
    "EMBEDDING_CHECKPOINTS_PATH = \"embedding_checkpoints\"\n",
    "EMBEDDING_CHECKPOINTS_PATH = \"embedding_checkpoints\"\n",
    "\n",
    "brands_in_csv_filename = [\"ad\",\n",
    "\"brabantsdagblad\",\n",
    "\"destentor\",\n",
    "\"nu\",\n",
    "\"parool\",\n",
    "\"trouw\",\n",
    "\"volkskrant\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = pd.concat([pd.read_csv(os.path.join(DIRPATH_DATA, f\"uva-relevance-windows-{brand_in_csv_filename}.csv\"), sep=\";\")\n",
    "                     for brand_in_csv_filename in brands_in_csv_filename], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmbedS1inE2(values, max):\n",
    "       values = (values / max) * torch.pi * 2\n",
    "       out = torch.stack([torch.cos(values), torch.sin(values)], dim=1)\n",
    "       return out\n",
    "\n",
    "\n",
    "def to_vector(x, idx):\n",
    "       d = ast.literal_eval(x)\n",
    "       vector = torch.zeros(len(idx))\n",
    "       for topic_str in d:\n",
    "              vector[idx[topic_str]] = d[topic_str]\n",
    "       return vector\n",
    "\n",
    "\n",
    "def to_ohe(column):\n",
    "       i2s = column.unique().tolist()\n",
    "       s2i = {s: i for i, s in enumerate(i2s)} \n",
    "\n",
    "       one_hot_encoder = torch.eye(len(i2s))\n",
    "       column_index = [s2i[row] for row in column]\n",
    "       \n",
    "       return one_hot_encoder[column_index]\n",
    "\n",
    "\n",
    "def to_brand_dir(feature_tensor, indices_dict, filename):\n",
    "       for brand in indices_dict:\n",
    "              dir_path_brand = os.path.join(DIRPATH_EXTRACTED_FEATURES, brand)\n",
    "              if not os.path.exists(dir_path_brand):\n",
    "                     os.makedirs(dir_path_brand)\n",
    "              file_path = os.path.join(dir_path_brand, filename)\n",
    "              torch.save(feature_tensor[indices_dict[brand]], file_path)\n",
    "\n",
    "\n",
    "def w2v_embedding(column, w2v_model):\n",
    "    # Get all unique main sections and create dict with their embeddings\n",
    "    column_indv = column.unique().tolist()\n",
    "    column_indv.remove(np.NaN)\n",
    "    column_emb_dict = {unique_val: torch.tensor(w2v_model.get_word_vector(unique_val)) for unique_val in column_indv}\n",
    "\n",
    "    # Add nan case to dict\n",
    "    column_emb_dict[np.NaN] = torch.zeros_like(list(column_emb_dict.values())[0])\n",
    "\n",
    "    # Initialize correct tensor shape and map all data point embeddings to feature tensor\n",
    "    column_emb = torch.empty(len(column), list(column_emb_dict.values())[0].shape[0])\n",
    "\n",
    "    for unique_val in column_emb_dict:\n",
    "        column_emb[data_pd.index[column == unique_val]] = column_emb_dict[unique_val]\n",
    "    \n",
    "    return column_emb"
    "              torch.save(feature_tensor[indices_dict[brand]], file_path)\n",
    "\n",
    "\n",
    "def w2v_embedding(column, w2v_model):\n",
    "    # Get all unique main sections and create dict with their embeddings\n",
    "    column_indv = column.unique().tolist()\n",
    "    column_indv.remove(np.NaN)\n",
    "    column_emb_dict = {unique_val: torch.tensor(w2v_model.get_word_vector(unique_val)) for unique_val in column_indv}\n",
    "\n",
    "    # Add nan case to dict\n",
    "    column_emb_dict[np.NaN] = torch.zeros_like(list(column_emb_dict.values())[0])\n",
    "\n",
    "    # Initialize correct tensor shape and map all data point embeddings to feature tensor\n",
    "    column_emb = torch.empty(len(column), list(column_emb_dict.values())[0].shape[0])\n",
    "\n",
    "    for unique_val in column_emb_dict:\n",
    "        column_emb[data_pd.index[column == unique_val]] = column_emb_dict[unique_val]\n",
    "    \n",
    "    return column_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = data_pd[\"brand\"].unique().tolist()\n",
    "\n",
    "brand_indices = {brand: torch.tensor(data_pd.index[data_pd['brand'] == brand]).int() for brand in brands}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_ohe = to_ohe(data_pd[\"brand\"])\n",
    "to_brand_dir(brand_ohe, brand_indices, utils.FILENAME_BRAND_OHE)\n",
    "\n",
    "minutes = []\n",
    "for row in data_pd[\"publication_timestamp\"]:\n",
    "       minutes.append(int(row[11:13]) * 60 + int(row[14:16]))\n",
    "minutes = torch.tensor(minutes)\n",
    "\n",
    "to_brand_dir(minutes.unsqueeze(1), brand_indices, utils.FILENAME_PUBLICATION_TIMESTAMP)\n",
    "\n",
    "minutes_S1 = EmbedS1inE2(minutes, 60*24)\n",
    "to_brand_dir(minutes_S1, brand_indices, utils.FILENAME_PUBLICATION_TIMESTAMP_EMB)\n",
    "\n",
    "weekday_ohe = to_ohe(data_pd[\"publication_weekday\"])\n",
    "to_brand_dir(weekday_ohe, brand_indices, utils.FILENAME_PUBLICATION_WEEKDAY_OHE)\n",
    "\n",
    "num_word = torch.tensor(data_pd['num_words']).unsqueeze(1)\n",
    "to_brand_dir(num_word, brand_indices, utils.FILENAME_NUM_WORDS)\n",
    "\n",
    "num_par = torch.tensor(data_pd['num_words']).unsqueeze(1)\n",
    "to_brand_dir(num_par, brand_indices, utils.FILENAME_NUM_PARAGRAPH)\n",
    "\n",
    "\n",
    "main_ohe = to_ohe(data_pd['main_section'])\n",
    "to_brand_dir(main_ohe, brand_indices, utils.FILENAME_MAIN_SECTION_OHE)\n",
    "\n",
    "subsections_ohe = to_ohe(data_pd['subsections'])\n",
    "to_brand_dir(subsections_ohe, brand_indices, utils.FILENAME_SUBSECTIONS_OHE)\n",
    "\n",
    "user_needs = torch.tensor(data_pd[\"user_needs\"].map(lambda user_needs: list(ast.literal_eval(user_needs).values())))\n",
    "to_brand_dir(user_needs, brand_indices, utils.FILENAME_USER_NEEDS)\n",
    "\n",
    "user_needs = torch.tensor(data_pd[\"user_needs\"].map(lambda user_needs: list(ast.literal_eval(user_needs).values())))\n",
    "to_brand_dir(user_needs, brand_indices, utils.FILENAME_USER_NEEDS)\n",
    "\n",
    "lda_topics = torch.tensor(data_pd[\"lda_topics\"].map(lambda lda_topics: list(ast.literal_eval(lda_topics).values())))\n",
    "to_brand_dir(lda_topics, brand_indices, utils.FILENAME_LDA_TOPICS)\n",
    "\n",
    "iptc_level_0 = set()\n",
    "for row in data_pd[\"iptc_topics_level_0\"]:\n",
    "       iptc_level_0 = iptc_level_0.union(set(ast.literal_eval(row).keys()))\n",
    "iptc_level_1 = set()\n",
    "for row in data_pd[\"iptc_topics_level_1\"]:\n",
    "       iptc_level_1 = iptc_level_1.union(set(ast.literal_eval(row).keys()))\n",
    "iptc_level_0_indexed = {topic_str: topic_id for topic_id, topic_str in enumerate(iptc_level_0)}\n",
    "iptc_level_1_indexed = {topic_str: topic_id for topic_id, topic_str in enumerate(iptc_level_1)}\n",
    "\n",
    "iptc_0 = torch.stack(data_pd['iptc_topics_level_0'].map(lambda x: to_vector(x, iptc_level_0_indexed)).tolist())\n",
    "to_brand_dir(iptc_0, brand_indices, utils.FILENAME_IPTC_TOPICS_LEVEL_0)\n",
    "\n",
    "iptc_1 = torch.stack(data_pd['iptc_topics_level_1'].map(lambda x: to_vector(x, iptc_level_1_indexed)).tolist())\n",
    "to_brand_dir(iptc_1, brand_indices, utils.FILENAME_IPTC_TOPICS_LEVEL_1)\n",
    "\n",
    "target = torch.FloatTensor(data_pd['relevance_window_in_hours']).unsqueeze(1)\n",
    "to_brand_dir(target, brand_indices, utils.FILENAME_RELEVANCE_WINDOW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = fasttext.load_model(os.path.join(EMBEDDING_CHECKPOINTS_PATH, 'cc.nl.300.bin'))\n",
    "\n",
    "main_section_emb = w2v_embedding(data_pd[\"main_section\"], w2v_model)\n",
    "to_brand_dir(main_section_emb, brand_indices, utils.FILENAME_MAIN_SECTION_EMB)\n",
    "\n",
    "subsections_emb = w2v_embedding(data_pd[\"subsections\"], w2v_model)\n",
    "to_brand_dir(main_section_emb, brand_indices, utils.FILENAME_SUBSECTIONS_EMB)\n",
    "to_brand_dir(target, brand_indices, utils.FILENAME_RELEVANCE_WINDOW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = fasttext.load_model(os.path.join(EMBEDDING_CHECKPOINTS_PATH, 'cc.nl.300.bin'))\n",
    "\n",
    "main_section_emb = w2v_embedding(data_pd[\"main_section\"], w2v_model)\n",
    "to_brand_dir(main_section_emb, brand_indices, utils.FILENAME_MAIN_SECTION_EMB)\n",
    "\n",
    "subsections_emb = w2v_embedding(data_pd[\"subsections\"], w2v_model)\n",
    "to_brand_dir(main_section_emb, brand_indices, utils.FILENAME_SUBSECTIONS_EMB)\n",
    "\n",
    "main_section_subsections_mean_emb = torch.mean(torch.stack([main_section_emb, subsections_emb]), dim=0)\n",
    "to_brand_dir(main_section_emb, brand_indices, utils.FILENAME_MAIN_SECTION_SUBSECTIONS_MEAN_EMB)"
    "main_section_subsections_mean_emb = torch.mean(torch.stack([main_section_emb, subsections_emb]), dim=0)\n",
    "to_brand_dir(main_section_emb, brand_indices, utils.FILENAME_MAIN_SECTION_SUBSECTIONS_MEAN_EMB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
