{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import dpctl\n",
    "print(dpctl.get_devices())\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "patch_sklearn()\n",
    "\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "device = 'cpu'\n",
    "DIR_PATH = \"Data\"\n",
    "DIRPATH_EXTRACTED_FEATURES = \"extracted_features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset():\n",
    "    def __init__(self, brands: list, filenames_features: list, filename_target=utils.FILENAME_RELEVANCE_WINDOW, log_target=False, device=device):\n",
    "        self.log_target = log_target\n",
    "        tensor = torch.concat([torch.concat([torch.load(os.path.join(DIRPATH_EXTRACTED_FEATURES, brand, filename_feature), map_location=device, weights_only=False) \n",
    "                                for filename_feature in filenames_features], dim=1)\n",
    "                                  for brand in brands], dim=0)\n",
    "        numpy_array = tensor.cpu().detach().numpy()\n",
    "        features = pd.DataFrame(numpy_array)\n",
    "\n",
    "        tensor = torch.concat([torch.load(os.path.join(DIRPATH_EXTRACTED_FEATURES, brand, filename_target), map_location=device, weights_only=False) \n",
    "                                  for brand in brands], dim=0)\n",
    "        numpy_array = tensor.cpu().detach().numpy()\n",
    "        self.target = pd.DataFrame(numpy_array)\n",
    "        self.target.rename(columns={0:'target'}, inplace=True)\n",
    "        if log_target:\n",
    "              self.target = np.log(self.target)\n",
    "\n",
    "        self.features_train, self.features_test, self.target_train, self.target_test = train_test_split(features, self.target, test_size = 0.1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    \n",
    "# class CustomDataset():\n",
    "#     def __init__(self, brands: list, filenames_features: list, filename_target=utils.FILENAME_RELEVANCE_WINDOW, log_target=False, device=device, percentile=100):\n",
    "#         self.log_target = log_target\n",
    "#         tensor = torch.concat([torch.concat([torch.load(os.path.join(DIRPATH_EXTRACTED_FEATURES, brand, filename_feature), map_location=device, weights_only=False) \n",
    "#                                 for filename_feature in filenames_features], dim=1)\n",
    "#                                   for brand in brands], dim=0)\n",
    "#         numpy_array = tensor.cpu().detach().numpy()\n",
    "#         features = pd.DataFrame(numpy_array)\n",
    "\n",
    "#         tensor = torch.concat([torch.load(os.path.join(DIRPATH_EXTRACTED_FEATURES, brand, filename_target), map_location=device, weights_only=False) \n",
    "#                                   for brand in brands], dim=0)\n",
    "#         numpy_array = tensor.cpu().detach().numpy()\n",
    "#         target = pd.DataFrame(numpy_array)\n",
    "#         target.rename(columns={0:'target'}, inplace=True)\n",
    "#         df = pd.concat([features, target], axis=1)\n",
    "#         target_counts = df['target'].value_counts()\n",
    "\n",
    "#         threshold = np.percentile(target_counts.values, percentile)\n",
    "#         to_downsample = target_counts[target_counts > threshold].index\n",
    "\n",
    "#         balanced_data = []\n",
    "#         for value in target_counts.index:\n",
    "#             subset = df[df['target'] == value]\n",
    "#             if value in to_downsample:\n",
    "#                 subset = subset.sample(int(threshold))\n",
    "#             balanced_data.append(subset)\n",
    "\n",
    "#         balanced_df = pd.concat(balanced_data)\n",
    "\n",
    "#         self.features = balanced_df.drop(columns=['target'])\n",
    "#         self.target = balanced_df.filter(['target'])\n",
    "#         if log_target:\n",
    "#               self.target = np.log(self.target)\n",
    "\n",
    "#         self.features_train, self.features_test, self.target_train, self.target_test = train_test_split(self.features, self.target, test_size = 0.1, random_state=0)\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.target)\n",
    "\n",
    "\n",
    "class CustomRegressor():\n",
    "    def __init__(self, range=None, percentile=100):\n",
    "        if range: # gave errors when range was zero\n",
    "            if range[0] == 0:\n",
    "                range[0] += 1\n",
    "        self.range = range\n",
    "        self.percentile = percentile\n",
    "        # regressor = HistGradientBoostingRegressor()\n",
    "        self.regressor = RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            criterion='squared_error',\n",
    "            # min_samples_split=150,\n",
    "            min_samples_leaf=50,\n",
    "            min_impurity_decrease=0,\n",
    "            max_depth=20,\n",
    "            oob_score=True,\n",
    "            random_state=0,\n",
    "            n_jobs=-1,\n",
    "            )\n",
    "        # self.regressor = GradientBoostingRegressor( # testing required\n",
    "        #     loss='squared_error',\n",
    "        #     learning_rate=0.1,\n",
    "        #     n_estimators=100,\n",
    "        #     subsample=.7,\n",
    "        #     criterion='squared_error',\n",
    "        #     min_samples_leaf=50, # new test req, prev overfitting\n",
    "        #     max_depth=None, # maybe upp this??\n",
    "        #     random_state=0, \n",
    "        # )\n",
    "        # self.regressor = AdaBoostRegressor( # requires base\n",
    "        #     estimator=regressor,\n",
    "        #     n_estimators=200,\n",
    "        #     learning_rate=1,\n",
    "        #     loss='square',\n",
    "        #     random_state=0,\n",
    "        #     )\n",
    "        # self.regressor = BaggingRegressor( # requires base\n",
    "        #     estimator=regressor,\n",
    "        #     n_estimators=20,\n",
    "        #     n_jobs=-1,\n",
    "        # )\n",
    "\n",
    "    def process_data(self, Data: CustomDataset) -> pd.DataFrame:\n",
    "        target_train = Data.target_train.rename(columns={0:'target'})\n",
    "        target_range = (target_train['target'].min(), target_train['target'].max() + 1)\n",
    "        if self.range:\n",
    "            target_range = self.range\n",
    "            if Data.log_target:\n",
    "                target_range = np.log(target_range)\n",
    "        df = pd.concat([Data.features_train, target_train], axis=1)\n",
    "        df = df[df['target'] >= target_range[0]]\n",
    "        df = df[df['target'] < target_range[1]]\n",
    "        \n",
    "        target_counts = df['target'].value_counts()\n",
    "\n",
    "        threshold = np.percentile(target_counts.values, self.percentile)\n",
    "        to_downsample = target_counts[target_counts > threshold].index\n",
    "\n",
    "        balanced_data = []\n",
    "        for value in target_counts.index:\n",
    "            subset = df[df['target'] == value]\n",
    "            if value in to_downsample:\n",
    "                subset = subset.sample(int(threshold))\n",
    "            balanced_data.append(subset)\n",
    "\n",
    "        return pd.concat(balanced_data)\n",
    "\n",
    "    def fit(self, Data: CustomDataset):\n",
    "        balanced_df = self.process_data(Data)\n",
    "        \n",
    "        features_train = balanced_df.drop(columns=['target'])\n",
    "        target_train = balanced_df['target']\n",
    "        \n",
    "        self.regressor.fit(features_train, target_train)\n",
    "\n",
    "    def oob_score(self):\n",
    "        print(f'Out-of-Bag Score: {self.regressor.oob_score_}')\n",
    "        \n",
    "    def score(self, Data: CustomDataset):\n",
    "        target_test = Data.target_test.rename(columns={0:'target'})\n",
    "        target_range = (target_test['target'].min(), target_test['target'].max() + 1)\n",
    "        if self.range:\n",
    "            if Data.log_target:\n",
    "                target_range = np.log(self.range)\n",
    "\n",
    "        df = pd.concat([Data.features_test, target_test], axis=1)\n",
    "        df = df[df['target'] >= target_range[0]]\n",
    "        df = df[df['target'] < target_range[1]]\n",
    "        features_test = df.drop(columns=['target'])\n",
    "        target_test = df['target']\n",
    "\n",
    "        predictions = self.regressor.predict(features_test)\n",
    "        # self.oob_score()\n",
    "        mse = mean_squared_error(target_test, predictions)\n",
    "        r2 = r2_score(target_test, predictions)\n",
    "        print(f'Mean Squared Error: {mse}')\n",
    "        print(f'R-squared: {r2}')\n",
    "\n",
    "    def predict_train(self, Data: CustomDataset):\n",
    "        return self.regressor.predict(Data.features_train)\n",
    "\n",
    "    def predict_test(self, Data: CustomDataset):\n",
    "        return self.regressor.predict(Data.features_test)\n",
    "    \n",
    "    def predict(self, Data):\n",
    "        return self.regressor.predict(Data)\n",
    "        \n",
    "\n",
    "class CustomClassifier():\n",
    "    def __init__(self, bins):\n",
    "        self.bins = bins\n",
    "        self.classifier = RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            criterion='gini',\n",
    "            max_depth=None,\n",
    "            min_samples_leaf=20,\n",
    "            oob_score=True,\n",
    "            random_state=0,\n",
    "        )\n",
    "        \n",
    "    def fit(self, Data: CustomDataset):\n",
    "        if Data.log_target:\n",
    "            train_bins = (Data.target_train).map(np.exp)\n",
    "        else:\n",
    "            train_bins = Data.target_train\n",
    "        train_bins = pd.cut(train_bins[0], bins=self.bins, labels=[i for i in range(len(self.bins) - 1)])\n",
    "        self.classifier.fit(Data.features_train, train_bins)\n",
    "\n",
    "    def oob_score(self):\n",
    "        print(f'Out-of-Bag Score: {self.classifier.oob_score_}')\n",
    "        \n",
    "    def score(self, Data: CustomDataset):\n",
    "        if Data.log_target:\n",
    "            train_bins = (Data.target_train).map(np.exp)\n",
    "            test_bins = (Data.target_test).map(np.exp)\n",
    "        else:\n",
    "            train_bins = Data.target_train\n",
    "            test_bins = Data.target_test\n",
    "        train_bins = pd.cut(train_bins[0], bins=self.bins, labels=[i for i in range(len(self.bins) - 1)])\n",
    "        test_bins = pd.cut(test_bins[0], bins=self.bins, labels=[i for i in range(len(self.bins) - 1)])\n",
    "\n",
    "        target_train_pred = self.classifier.predict(Data.features_train)\n",
    "        target_test_pred = self.classifier.predict(Data.features_test)\n",
    "        train_accuracy = accuracy_score(train_bins, target_train_pred)\n",
    "        test_accuracy = accuracy_score(test_bins, target_test_pred)\n",
    "\n",
    "        self.oob_score()\n",
    "        print(\"Train Accuracy: %.1f%%\" %(train_accuracy * 100))\n",
    "        print(\"Test Accuracy: %.1f%%\" %(test_accuracy * 100))\n",
    "\n",
    "    def predict_train(self, Data: CustomDataset):\n",
    "        return self.classifier.predict(Data.features_train)\n",
    "\n",
    "    def predict_test(self, Data: CustomDataset):\n",
    "        print(Data.target_test)\n",
    "        return self.classifier.predict(Data.features_test)\n",
    "    \n",
    "    def predict(self, Data):\n",
    "        return self.classifier.predict(Data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_features = [\n",
    "    utils.FILENAME_BRAND_OHE, # 7\n",
    "    utils.FILENAME_PUBLICATION_TIMESTAMP, # 1\n",
    "    utils.FILENAME_PUBLICATION_WEEKDAY_OHE, # 7\n",
    "    utils.FILENAME_NUM_WORDS, # 1\n",
    "    utils.FILENAME_NUM_PARAGRAPH, # 1\n",
    "    # utils.FILENAME_MAIN_SECTION_OHE, # 118\n",
    "    # utils.FILENAME_MAIN_SECTION_EMB, # 300\n",
    "    # utils.FILENAME_SUBSECTIONS_OHE, # 959\n",
    "    # utils.FILENAME_SUBSECTIONS_EMB, # 300\n",
    "    # utils.FILENAME_MAIN_SECTION_SUBSECTIONS_MEAN_EMB, # 300\n",
    "    utils.FILENAME_USER_NEEDS, # 5\n",
    "    utils.FILENAME_LDA_TOPICS, # 36\n",
    "    utils.FILENAME_IPTC_TOPICS_LEVEL_0, # 17\n",
    "    utils.FILENAME_IPTC_TOPICS_LEVEL_1, # 98\n",
    "]\n",
    "\n",
    "brands = utils.ALL_BRANDS\n",
    "# brands = ['ad']\n",
    "# brands = ['brabantsdagblad']\n",
    "# brands = ['destentor']\n",
    "# brands = ['nu']\n",
    "# brands = ['parool']\n",
    "# brands = ['trouw']\n",
    "# brands = ['volkskrant']\n",
    "# brands = ['ad', 'brabantsdagblad', 'destentor']\n",
    "# brands = ['parool', 'trouw', 'volkskrant']\n",
    "\n",
    "bins = [0, 30, 60, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = CustomDataset(brands, filenames_features, log_target=True)\n",
    "Data.features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_twentyfour = np.log(24)\n",
    "if Data.log_target:\n",
    "    target_pred = [log_twentyfour for _ in range(len(Data.target_test))]\n",
    "else:\n",
    "    target_pred = [24 for _ in range(len(Data.target_test))]\n",
    "\n",
    "# print(mean_absolute_error(Data.target_test, target_pred))\n",
    "print(mean_squared_error(Data.target_test, target_pred))\n",
    "print(r2_score(Data.target_test, target_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # to skip cell, analysing data\n",
    "\n",
    "df = Data.target\n",
    "target_counts = df[0].value_counts()\n",
    "\n",
    "threshold = np.percentile(target_counts.values, 99.5)\n",
    "to_downsample = target_counts[target_counts > threshold].index\n",
    "\n",
    "balanced_data = []\n",
    "for value in target_counts.index:\n",
    "    subset = df[df[0] == value]\n",
    "    if value in to_downsample:\n",
    "        subset = subset.sample(int(threshold))\n",
    "    balanced_data.append(subset)\n",
    "\n",
    "# Combine back into a single dataframe\n",
    "balanced_df = pd.concat(balanced_data)\n",
    "balanced_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error # to skip cell, analysing data\n",
    "\n",
    "regressor = CustomRegressor(percentile=99.5)\n",
    "\n",
    "ground_truth_orderd = regressor.process_data(Data)['target'].value_counts().sort_index()\n",
    "# his_bins = np.histogram(ground_truth_orderd, bins=len(ground_truth_orderd.unque()))\n",
    "ground_truth_orderd = ground_truth_orderd\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(ground_truth_orderd.index,ground_truth_orderd.values)  # Adjust bins for readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error # to skip cell, simple forests \n",
    "\n",
    "regressor.fit(Data)\n",
    "print('regressor:')\n",
    "regressor.score(Data)\n",
    "\n",
    "# classifier = CustomClassifier(bins=bins)\n",
    "# classifier.fit(Data)\n",
    "# print('classifier:')\n",
    "# classifier.score(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error # to skip cell, simple forests \n",
    "\n",
    "y_train = pd.DataFrame(Data.target_train).rename(columns={'target':0})\n",
    "y_pred_train = pd.DataFrame(regressor.predict_train(Data), index=y_train.index)\n",
    "abs_dif_train = (y_pred_train - y_train).apply(lambda x:x**2)\n",
    "\n",
    "y_test = pd.DataFrame(Data.target_test).rename(columns={'target':0})\n",
    "y_pred_test = pd.DataFrame(regressor.predict_test(Data), index=y_test.index)\n",
    "abs_dif_test = (y_pred_test - y_test).apply(lambda x:x**2)\n",
    "\n",
    "# print('mse train:\\n', mean_squared_error(y_train, y_pred_train))\n",
    "# print('r2 train:\\n', r2_score(y_train, y_pred_train))\n",
    "# print('mse test:\\n', mean_squared_error(y_test, y_pred_test))\n",
    "# print('r2 test:\\n', r2_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # to skip cell, simple forests \n",
    "import torch.nn as nn\n",
    "metric = nn.MSELoss(reduction='none')\n",
    "\n",
    "y_train = pd.DataFrame(Data_full.target_train).rename(columns={'target':0})\n",
    "y_pred_train = pd.DataFrame(regressor.predict_train(Data_full))\n",
    "abs_dif_train = metric(y_pred_train, y_train)\n",
    "\n",
    "y_test = pd.DataFrame(Data_full.target_test).rename(columns={'target':0})\n",
    "y_pred_test = pd.DataFrame(regressor.predict_test(Data_full))\n",
    "abs_dif_test = metric(y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # to skip cell, custom forests \n",
    "\n",
    "regressors = []\n",
    "for n, lower in enumerate(bins[:-1]):\n",
    "    regressors.append(CustomRegressor([lower, bins[n + 1]]))\n",
    "\n",
    "regressors = [] # testing something\n",
    "for i in range(len(bins) - 1):\n",
    "    if i == 0:\n",
    "        lower = bins[i]\n",
    "    else:\n",
    "        lower = bins[i - 1]\n",
    "    if i == len(bins) - 2:\n",
    "        higher = bins[i + 1]\n",
    "    else:\n",
    "        higher = bins[i + 2]\n",
    "    regressors.append(CustomRegressor([lower, higher]))\n",
    "\n",
    "classifier = CustomClassifier(bins)\n",
    "\n",
    "for regressor in regressors:\n",
    "    regressor.fit(Data)\n",
    "    print(f'Regressor {regressor.range} trained')\n",
    "\n",
    "classifier.fit(Data)\n",
    "print('Classifier trained')\n",
    "\n",
    "def class_regression(features):\n",
    "    bin_predictions = classifier.predict(features)\n",
    "\n",
    "    final_predictions = []\n",
    "    for i, bin_idx in enumerate(bin_predictions):\n",
    "        final_predictions.append(regressors[bin_idx].predict(features.iloc[[i]])[0])\n",
    "\n",
    "    return pd.DataFrame(final_predictions, columns=[0])\n",
    "\n",
    "final_predictions_test = class_regression(Data.features_test)\n",
    "print(\"Final test predictions made\")\n",
    "\n",
    "final_predictions_train = class_regression(Data.features_train)\n",
    "print(\"Final train predictions made\")\n",
    "\n",
    "y_train = pd.DataFrame(Data.target_train)\n",
    "y_pred_train = final_predictions_train\n",
    "abs_dif_train = (y_pred_train - y_train).map(np.abs)\n",
    "\n",
    "y_test = pd.DataFrame(Data.target_test)\n",
    "y_pred_test = final_predictions_test\n",
    "abs_dif_test = (y_pred_test - y_test).map(np.abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # to skip cell, simple forests \n",
    "\n",
    "print('m_absolute_error: ',mean_absolute_error(Data.target_test, final_predictions_test))\n",
    "print('m_squared_error: ',mean_squared_error(Data.target_test, final_predictions_test))\n",
    "print('m_squared_error_exped: ',mean_squared_error((Data.target_test).map(np.exp), (final_predictions_test).map(np.exp)))\n",
    "print('r2_score: ',r2_score(Data.target_test, final_predictions_test))\n",
    "\n",
    "print('classifier:')\n",
    "classifier.score(Data)\n",
    "\n",
    "for regressor in regressors:\n",
    "    print(f'regressor {regressor.range}:')\n",
    "    regressor.score(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train \\n diff mean: {abs_dif_train.mean()[0]}, diff std: {abs_dif_train.std()[0]}')\n",
    "print(f'test \\n diff mean: {abs_dif_test.mean()[0]}, diff std: {abs_dif_test.std()[0]}')\n",
    "plt.hist(abs_dif_train, bins=50, alpha=0.5, color='b')\n",
    "plt.title('Difference of the prediction and real training data')\n",
    "plt.show()\n",
    "plt.hist(abs_dif_test, bins=50, alpha=0.5, color='b')\n",
    "plt.title('Difference of the prediction and real test data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 100\n",
    "bins = np.histogram(np.hstack((y_pred_train,y_train)), bins=n_bins)[1]\n",
    "plt.hist(y_pred_train, bins=bins, alpha=0.5, color='b', label='train prediction')\n",
    "plt.hist(y_train, bins=bins, alpha=0.5, color='r', label='train ground truth')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "bins = np.histogram(np.hstack((y_pred_test,y_test)), bins=n_bins)[1]\n",
    "plt.hist(y_pred_test, bins=bins, alpha=0.5, color='b', label='test prediction')\n",
    "plt.hist(y_test, bins=bins, alpha=0.5, color='r', label='test ground truth')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "if Data.log_target:\n",
    "    y_pred_train_trans = (y_pred_train).map(np.exp)\n",
    "    y_train_trans = (y_train).map(np.exp)\n",
    "    y_pred_test_trans = (y_pred_test).map(np.exp)\n",
    "    y_test_trans = (y_test).map(np.exp)\n",
    "else:\n",
    "    y_pred_train_trans = (y_pred_train).map(np.log)\n",
    "    y_train_trans = (y_train).map(np.log)\n",
    "    y_pred_test_trans = (y_pred_test).map(np.log)\n",
    "    y_test_trans = (y_test).map(np.log)\n",
    "\n",
    "bins = np.histogram(np.hstack((y_pred_train_trans,y_train_trans)), bins=n_bins)[1]\n",
    "plt.hist(y_pred_train_trans, bins=bins, alpha=0.5, color='b', label='train prediction')\n",
    "plt.hist(y_train_trans, bins=bins, alpha=0.5, color='r', label='train ground truth')\n",
    "# plt.xlim(xmin=1, xmax = 200)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "bins = np.histogram(np.hstack((y_pred_test_trans,y_test_trans)), bins=n_bins)[1]\n",
    "plt.hist(y_pred_test_trans, bins=bins, alpha=0.5, color='b', label='test prediction')\n",
    "plt.hist(y_test_trans, bins=bins, alpha=0.5, color='r', label='test ground truth')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "def plotting_tree(tree):\n",
    "    # print(\"Worker thread running\")\n",
    "    n, tree_to_plot = tree\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plot_tree(tree_to_plot, feature_names=Data.features_train.columns.tolist(), filled=True, rounded=True, fontsize=10)\n",
    "    plt.title(f\"Decision Tree {n} from Random Forest\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree in enumerate(regressor.regressor.estimators_):\n",
    "    i, _ = tree\n",
    "    if i == 0:\n",
    "        plotting_tree(tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
