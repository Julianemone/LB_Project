{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever there is a <br>\n",
    "%%script false --no-raise-error <br>\n",
    "comment it to use the cell, and comment it to skip the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "##########################################################\n",
    "### not needed if you do not want the package\n",
    "### can be removed without problem\n",
    "##########################################################\n",
    "import dpctl\n",
    "print(dpctl.get_devices())\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "device = 'cpu'\n",
    "DIR_PATH = \"Data\"\n",
    "DIRPATH_EXTRACTED_FEATURES = \"extracted_features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "### section needed for fair comparison with MLP\n",
    "### can be removed without problem\n",
    "##########################################################\n",
    "import pickle\n",
    "\n",
    "with open('data_split_indices/train_dataset_indices.pkl', 'rb') as f:\n",
    "    train_dataset_indices = pickle.load(f)\n",
    "\n",
    "with open('data_split_indices/val_dataset_indices.pkl', 'rb') as f:\n",
    "    val_dataset_indices = pickle.load(f)\n",
    "\n",
    "with open('data_split_indices/test_dataset_indices.pkl', 'rb') as f:\n",
    "    test_dataset_indices = pickle.load(f)\n",
    "\n",
    "print(len(train_dataset_indices))\n",
    "print(len(val_dataset_indices))\n",
    "print(len(test_dataset_indices))\n",
    "\n",
    "def fix_seed(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "fix_seed(utils.SEED)\n",
    "#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset():\n",
    "    def __init__(self, brands: list, filenames_features: list, filename_target=utils.FILENAME_RELEVANCE_WINDOW, log_target=False, center_target=False, device=device):\n",
    "        self.log_target = log_target\n",
    "        self.center_target = center_target\n",
    "\n",
    "        tensor = torch.concat([torch.concat([torch.load(os.path.join(DIRPATH_EXTRACTED_FEATURES, brand, filename_feature), map_location=device, weights_only=False) \n",
    "                                for filename_feature in filenames_features], dim=1)\n",
    "                                  for brand in brands], dim=0)\n",
    "        numpy_array = tensor.cpu().detach().numpy()\n",
    "        features = pd.DataFrame(numpy_array)\n",
    "\n",
    "        tensor = torch.concat([torch.load(os.path.join(DIRPATH_EXTRACTED_FEATURES, brand, filename_target), map_location=device, weights_only=False) \n",
    "                                  for brand in brands], dim=0)\n",
    "        numpy_array = tensor.cpu().detach().numpy()\n",
    "        target = pd.DataFrame(numpy_array)\n",
    "        target.rename(columns={0:'target'}, inplace=True)\n",
    "\n",
    "        if log_target:\n",
    "              target = np.log(target)\n",
    "        if center_target:\n",
    "            self.centering_shift = target.mean()\n",
    "            target = target - self.centering_shift\n",
    "\n",
    "        ###################################################\n",
    "        ### section needed for fair comparison with MLP\n",
    "        ### can be removed without problem\n",
    "        ###################################################\n",
    "        dataset = pd.concat([features, target], axis=1)\n",
    "        dataset_test = dataset.loc[test_dataset_indices]\n",
    "        dataset_rest = dataset.drop(index=test_dataset_indices)\n",
    "\n",
    "        self.features_final_test = dataset_test.drop(columns=['target'])\n",
    "        self.target_final_test = dataset_test.filter(['target'])\n",
    "\n",
    "        features = dataset_rest.drop(columns=['target'])\n",
    "        target = dataset_rest.filter(['target'])\n",
    "        #%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#%#\n",
    "\n",
    "        self.features_train, self.features_test, self.target_train, self.target_test = train_test_split(features, target, test_size = 1/9)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    \n",
    "class CustomRegressor():\n",
    "    def __init__(self, percentile=100):\n",
    "        self.percentile = percentile\n",
    "\n",
    "        self.weight_fun = lambda x: -60 * np.e ** (-0.5 * np.abs(x - 24)) + 100 + 0.0003 * (x - 24) ** 2\n",
    "        # self.weight_fun = lambda x: -150 * np.e ** (-0.01 * np.abs(x - 26)) + 200\n",
    "\n",
    "        self.regressor = RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            criterion='squared_error',\n",
    "            min_samples_split=150,\n",
    "            min_samples_leaf=50,\n",
    "            max_depth=20,\n",
    "            max_samples=.5,\n",
    "            oob_score=True,\n",
    "            random_state=0,\n",
    "            n_jobs=-1,\n",
    "            )\n",
    "\n",
    "    def process_data(self, Data: CustomDataset) -> pd.DataFrame:\n",
    "        target_train = Data.target_train.rename(columns={0:'target'})\n",
    "        \n",
    "        df = pd.concat([Data.features_train, target_train], axis=1)\n",
    "        target_counts = df['target'].value_counts()\n",
    "\n",
    "        threshold = np.percentile(target_counts.values, self.percentile)\n",
    "        to_downsample = target_counts[target_counts > threshold].index\n",
    "\n",
    "        balanced_data = []\n",
    "        for value in target_counts.index:\n",
    "            subset = df[df['target'] == value]\n",
    "            if value in to_downsample:\n",
    "                subset = subset.sample(int(threshold))\n",
    "            balanced_data.append(subset)\n",
    "\n",
    "        return pd.concat(balanced_data)\n",
    "\n",
    "    def fit(self, Data: CustomDataset, weighted = False):\n",
    "        balanced_df = self.process_data(Data)\n",
    "        \n",
    "        features_train = balanced_df.drop(columns=['target'])\n",
    "        target_train = balanced_df['target']\n",
    "        \n",
    "        if weighted:\n",
    "            if Data.log_target:\n",
    "                weigths = (target_train).map(np.exp).apply(self.weight_fun)\n",
    "            else:\n",
    "                weigths = target_train.apply(self.weight_fun)\n",
    "\n",
    "            print(weigths.sort_values()) # TODO remove line\n",
    "        else:\n",
    "            weigths = None\n",
    "\n",
    "        self.regressor.fit(features_train, target_train, weigths)\n",
    "\n",
    "    def oob_score(self):\n",
    "        print(f'Out-of-Bag Score: {self.regressor.oob_score_}')\n",
    "        \n",
    "    def score(self, Data: CustomDataset):\n",
    "        target_test = Data.target_test.rename(columns={0:'target'})\n",
    "        predictions = self.regressor.predict(Data.features_test)\n",
    "\n",
    "        self.oob_score()\n",
    "        mse = mean_squared_error(target_test, predictions)\n",
    "        r2 = r2_score(target_test, predictions)\n",
    "        print(f'Mean Squared Error: {mse}')\n",
    "        print(f'R-squared: {r2}')\n",
    "\n",
    "    def predict_train(self, Data: CustomDataset):\n",
    "        return self.regressor.predict(Data.features_train)\n",
    "\n",
    "    def predict_test(self, Data: CustomDataset):\n",
    "        return self.regressor.predict(Data.features_test)\n",
    "    \n",
    "    def predict(self, Data):\n",
    "        return self.regressor.predict(Data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_features = [                      # dimensions\n",
    "    utils.FILENAME_BRAND_OHE,               # 7\n",
    "    utils.FILENAME_PUBLICATION_TIMESTAMP,   # 1\n",
    "    utils.FILENAME_PUBLICATION_WEEKDAY_OHE, # 7\n",
    "    utils.FILENAME_NUM_WORDS,               # 1\n",
    "    utils.FILENAME_NUM_PARAGRAPH,           # 1\n",
    "    utils.FILENAME_USER_NEEDS,              # 5\n",
    "    utils.FILENAME_LDA_TOPICS,              # 36\n",
    "    utils.FILENAME_IPTC_TOPICS_LEVEL_0,     # 17\n",
    "    utils.FILENAME_IPTC_TOPICS_LEVEL_1,     # 98\n",
    "    # utils.FILENAME_MAIN_SECTION_OHE,      # 118\n",
    "    # utils.FILENAME_MAIN_SECTION_EMB,      # 300\n",
    "    # utils.FILENAME_SUBSECTIONS_OHE,       # 959\n",
    "    # utils.FILENAME_SUBSECTIONS_EMB,       # 300\n",
    "    utils.FILENAME_MAIN_SECTION_SUBSECTIONS_MEAN_EMB, # 300\n",
    "    # utils.FILENAME_TITLE_EMB,             # 768\n",
    "    utils.FILENAME_AUTHOR_OHE,              # 2024\n",
    "]\n",
    "\n",
    "brands = utils.ALL_BRANDS\n",
    "# brands = ['ad']\n",
    "# brands = ['brabantsdagblad']\n",
    "# brands = ['destentor']\n",
    "# brands = ['nu']\n",
    "# brands = ['parool']\n",
    "# brands = ['trouw']\n",
    "# brands = ['volkskrant']\n",
    "# brands = ['ad', 'brabantsdagblad', 'destentor'] # papers with similar data\n",
    "# brands = ['parool', 'trouw', 'volkskrant']      # papers with similar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = CustomDataset(brands, filenames_features, log_target=True, center_target=False)\n",
    "Data.features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "log_twentyfour = np.log(24)\n",
    "if Data.log_target:\n",
    "    target_pred = [log_twentyfour for _ in range(len(Data.target_test))]\n",
    "else:\n",
    "    target_pred = [24 for _ in range(len(Data.target_test))]\n",
    "\n",
    "# print(mean_absolute_error(Data.target_test, target_pred))\n",
    "print(mean_squared_error(Data.target_test, target_pred))\n",
    "print(r2_score(Data.target_test, target_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = CustomRegressor(percentile=100)\n",
    "\n",
    "# plots used data\n",
    "ground_truth_orderd = regressor.process_data(Data)['target'].value_counts().sort_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(ground_truth_orderd.index, ground_truth_orderd.values)\n",
    "plt.show()\n",
    "\n",
    "# plots curve for weigths \n",
    "if regressor.weight_fun:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    xgrid = np.linspace(0, 600, 10000)\n",
    "    ygrid = [regressor.weight_fun(x) for x in xgrid]\n",
    "    plt.plot(xgrid, ygrid)\n",
    "    plt.ylim(0)\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error # to skip cell, simple forests \n",
    "\n",
    "regressor.fit(Data, True)\n",
    "print('regressor:')\n",
    "regressor.score(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # gridsearch\n",
    "\n",
    "# base\n",
    "clf = RandomForestRegressor(\n",
    "    criterion='squared_error',\n",
    "    oob_score=True,\n",
    "    n_jobs=-1,\n",
    "    n_estimators=100,\n",
    "    min_samples_split=100,\n",
    "    min_samples_leaf=20,\n",
    "    max_depth=40,\n",
    "    max_samples=.9\n",
    "    )\n",
    "\n",
    "# to check\n",
    "param_list = {\n",
    "    # 'n_estimators': [100, 250],\n",
    "    # \"min_samples_split\": np.arange(2, 20, 5),\n",
    "    # 'min_samples_leaf': [1, 20, 50, 150],\n",
    "    \"max_depth\": [20, 60],\n",
    "    'max_samples': [.5, .9, 1],\n",
    "}\n",
    "\n",
    "# checking using grid\n",
    "search = GridSearchCV(\n",
    "    clf, \n",
    "    param_list,\n",
    "    n_jobs=-1,\n",
    "    ).fit(Data.features_train, Data.target_train['target'])\n",
    "\n",
    "# to check\n",
    "# param_distributions = {\n",
    "#     # 'n_estimators': randint(150, 300),\n",
    "#     \"min_samples_split\": randint(2, 100),\n",
    "#     'min_samples_leaf': randint(1, 100),\n",
    "#     \"max_depth\": randint(40, 60),\n",
    "#     }\n",
    "\n",
    "# checking using random search\n",
    "# search = HalvingRandomSearchCV(\n",
    "#     clf, \n",
    "#     param_distributions,\n",
    "#     factor=2,\n",
    "#     n_candidates=300,\n",
    "#     random_state=0,\n",
    "#     max_resources=300,\n",
    "#     resource='n_estimators',\n",
    "#     n_jobs=-1,\n",
    "#     ).fit(Data.features_train, Data.target_train['target'])\n",
    "\n",
    "print(search.best_params_)\n",
    "search.score(Data.features_test, Data.target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error # to skip cell, simple forests \n",
    "\n",
    "y_train = pd.DataFrame(Data.target_train).rename(columns={'target':0})\n",
    "y_pred_train = pd.DataFrame(regressor.predict(Data.features_train), index=y_train.index)\n",
    "abs_dif_train = (y_pred_train - y_train).apply(lambda x:x**2)\n",
    "\n",
    "y_val = pd.DataFrame(Data.target_test).rename(columns={'target':0})\n",
    "y_pred_val = pd.DataFrame(regressor.predict(Data.features_test), index=y_val.index)\n",
    "abs_dif_val = (y_pred_val - y_val).apply(lambda x:x**2)\n",
    "\n",
    "y_test = pd.DataFrame(Data.target_final_test).rename(columns={'target':0})\n",
    "y_pred_test = pd.DataFrame(regressor.predict(Data.features_final_test), index=y_test.index)\n",
    "abs_dif_test = (y_pred_test - y_test).apply(lambda x:x**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regressor.regressor.get_params())\n",
    "print(f'train \\ndiff mean: {abs_dif_train.mean()[0]}, diff std: {abs_dif_train.std()[0]}')\n",
    "print(f'val \\ndiff mean: {abs_dif_val.mean()[0]}, diff std: {abs_dif_val.std()[0]}')\n",
    "print(f'test \\ndiff mean: {abs_dif_test.mean()[0]}, diff std: {abs_dif_test.std()[0]}')\n",
    "plt.hist(abs_dif_train, bins=50, alpha=0.5, color='b')\n",
    "plt.title('Difference of the prediction and real training data')\n",
    "plt.show()\n",
    "plt.hist(abs_dif_test, bins=50, alpha=0.5, color='b')\n",
    "plt.title('Difference of the prediction and real test data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # checking worst prediction\n",
    "df = pd.concat([pd.read_csv(f'Data/uva-relevance-windows-{brand}.csv', sep=';')\n",
    "                 for brand in brands]).reset_index()\n",
    "\n",
    "most = abs_dif_test.sort_values(ascending=True, by=0)[0:10:1]\n",
    "# most = abs_dif_test.sort_values(ascending=False, by=0)[0:1000:100]\n",
    "# most = abs_dif_test.sort_values(ascending=False, by=0)[0:20000:1000]\n",
    "\n",
    "df = df.loc[most.index]\n",
    "# validation = y_test.loc[most.index].apply(lambda x: np.exp(x))\n",
    "y_prediction = y_pred_test.loc[most.index].apply(lambda x: np.exp(x)).rename(columns={0:'prediction'})\n",
    "\n",
    "most = most.apply(lambda x: np.sqrt(x))\n",
    "most_values = pd.DataFrame(most.values, index=df.index).rename(columns={0:'RMSE'})\n",
    "df = pd.concat([df, y_prediction, most_values], axis=1)\n",
    "\n",
    "print(len(abs_dif_test))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 60\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = ('white') \n",
    "plt.gca().set_facecolor('white')\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (6.8,7)\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 13\n",
    "BIGGER_SIZE = 18\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)   # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "bins = np.histogram(np.hstack((y_pred_train,y_train)), bins=n_bins)[1]\n",
    "plt.hist(y_pred_train, bins=bins, alpha=0.5, color='b', label='Train prediction')\n",
    "plt.hist(y_train, bins=bins, alpha=0.5, color='r', label='Train ground truth')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Centred log of relevance window in hours\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "bins = np.histogram(np.hstack((y_pred_test,y_test)), bins=n_bins)[1]\n",
    "plt.hist(y_pred_test, bins=bins, alpha=0.5, color='b', label='Test prediction')\n",
    "plt.hist(y_test, bins=bins, alpha=0.5, color='r', label='Test ground truth')\n",
    "# plt.xlim(-3, 3)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Centred log of relevance window in hours\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "y_pred_train_trans = y_pred_train\n",
    "y_train_trans = y_train\n",
    "y_pred_test_trans = y_pred_test\n",
    "y_test_trans = y_test\n",
    "\n",
    "if Data.center_target:\n",
    "    centering_shift = Data.centering_shift\n",
    "    y_pred_train_trans = y_pred_train_trans + centering_shift\n",
    "    y_train_trans = y_train_trans + centering_shift\n",
    "    y_pred_test_trans = y_pred_test_trans + centering_shift\n",
    "    y_test_trans = y_test_trans + centering_shift\n",
    "if Data.log_target:\n",
    "    y_pred_train_trans = (y_pred_train_trans).map(np.exp)\n",
    "    y_train_trans = (y_train_trans).map(np.exp)\n",
    "    y_pred_test_trans = (y_pred_test_trans).map(np.exp)\n",
    "    y_test_trans = (y_test_trans).map(np.exp)\n",
    "else:\n",
    "    y_pred_train_trans = (y_pred_train_trans).map(np.log)\n",
    "    y_train_trans = (y_train_trans).map(np.log)\n",
    "    y_pred_test_trans = (y_pred_test_trans).map(np.log)\n",
    "    y_test_trans = (y_test_trans).map(np.log)\n",
    "\n",
    "\n",
    "bins = np.histogram(np.hstack((y_pred_train_trans,y_train_trans)), bins=n_bins)[1]\n",
    "plt.hist(y_pred_train_trans, bins=bins, alpha=0.5, color='b', label='train prediction')\n",
    "plt.hist(y_train_trans, bins=bins, alpha=0.5, color='r', label='train ground truth')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Relevance window in hours\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "bins = np.histogram(np.hstack((y_pred_test_trans,y_test_trans)), bins=n_bins)[1]\n",
    "plt.hist(y_pred_test_trans, bins=bins, alpha=0.5, color='b', label='test prediction')\n",
    "plt.hist(y_test_trans, bins=bins, alpha=0.5, color='r', label='test ground truth')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Relevance window in hours\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "def plotting_tree(tree):\n",
    "    n, tree_to_plot = tree\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plot_tree(tree_to_plot, feature_names=Data.features_train.columns.tolist(), filled=True, rounded=True, fontsize=10)\n",
    "    plt.title(f\"Decision Tree {n} from Random Forest\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree in enumerate(regressor.regressor.estimators_):\n",
    "    i, _ = tree\n",
    "    if i == 0:\n",
    "        plotting_tree(tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
