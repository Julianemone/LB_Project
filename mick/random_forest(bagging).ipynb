{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import sklearn\n",
    "import warnings\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_time(timestamp):\n",
    "       time = int(timestamp[11:13]) * 60 + int(timestamp[14:16])\n",
    "       return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_of_max(d):\n",
    "    try:\n",
    "        return max(d, key = d.get)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "using = {1,2,3,4,5,6,7} # all\n",
    "# using = {1,2,3,4} # shorties\n",
    "# using = {5,6,7} # longers\n",
    "# using = {1} # ad\n",
    "# using = {5,6} # custom\n",
    "\n",
    "papers = ['ad', 'brabantsdagblad', 'destentor', 'nu', 'parool', 'trouw', 'volksrant']\n",
    "features = ['brand', 'publication_timestamp', 'iptc_topics_level_0', 'iptc_topics_level_1', 'num_words', 'main_section', 'user_needs', 'lda_topics']\n",
    "# features = ['brand', 'iptc_topics_level_0', 'iptc_topics_level_1']\n",
    "target = 'relevance_window_in_hours'\n",
    "df = None\n",
    "\n",
    "with open('stop_words') as file:\n",
    "    stop_words = file.read().split()\n",
    "papers = [papers[x - 1] for x in using]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 in using:\n",
    "    df = pd.concat([df, pd.read_csv('dataset/uva-relevance-windows-ad.csv', sep=';')], ignore_index=True)\n",
    "    # ad: has 99122 entries\n",
    "    # target mean: 38.9\n",
    "\n",
    "if 2 in using:\n",
    "    df = pd.concat([df, pd.read_csv('dataset/uva-relevance-windows-brabantsdagblad.csv', sep=';')], ignore_index=True)\n",
    "    # brabantsdagblad: has 34768 entries\n",
    "    # target mean: 31.8\n",
    "\n",
    "if 3 in using:\n",
    "    df = pd.concat([df, pd.read_csv('dataset/uva-relevance-windows-destentor.csv', sep=';')], ignore_index=True)\n",
    "    # destentor: has 36212 entries\n",
    "    # target mean: 33.3\n",
    "    \n",
    "if 4 in using:\n",
    "    df = pd.concat([df, pd.read_csv('dataset/uva-relevance-windows-nu.csv', sep=';')], ignore_index=True)\n",
    "    # nu: has 16257 entries\n",
    "    # target mean: 29.4\n",
    "\n",
    "if 5 in using:\n",
    "    df = pd.concat([df, pd.read_csv('dataset/uva-relevance-windows-parool.csv', sep=';')], ignore_index=True)\n",
    "    # parool: has 7729 entries\n",
    "    # target mean: 88.8\n",
    "\n",
    "if 6 in using:\n",
    "    df = pd.concat([df, pd.read_csv('dataset/uva-relevance-windows-trouw.csv', sep=';')], ignore_index=True)\n",
    "    # trouw: has 8395 entries\n",
    "    # target mean: 93.2\n",
    "\n",
    "if 7 in using:\n",
    "    df = pd.concat([df, pd.read_csv('dataset/uva-relevance-windows-volkskrant.csv', sep=';')], ignore_index=True)\n",
    "    # volkskrant: has 10983 entries\n",
    "    # target mean: 90.5\n",
    "\n",
    "\n",
    "# df = df[df[target] < 48]\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df.head()\n",
    "df.info()\n",
    "# df.value_counts('user_needs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(features + [target])\n",
    "\n",
    "if 'iptc_topics_level_0' in features:\n",
    "    df['iptc_topics_level_0'] = df['iptc_topics_level_0'].map(eval)\n",
    "    df['iptc_topics_level_0'] = df['iptc_topics_level_0'].map(key_of_max)\n",
    "\n",
    "if 'iptc_topics_level_1' in features:\n",
    "    df['iptc_topics_level_1'] = df['iptc_topics_level_1'].map(eval)\n",
    "    df['iptc_topics_level_1'] = df['iptc_topics_level_1'].map(key_of_max)\n",
    "\n",
    "if 'publication_timestamp' in features:\n",
    "    df['publication_timestamp'] = df['publication_timestamp'].map(Extract_time)\n",
    "\n",
    "if 'user_needs' in features:\n",
    "    df['user_needs'] = df['user_needs'].map(eval)\n",
    "    # df['user_needs'] = df['user_needs'].map(key_of_max) # testing\n",
    "\n",
    "    normalized_info = pd.json_normalize(df['user_needs'])\n",
    "    df = pd.concat([df.drop(columns=['user_needs']), normalized_info], axis=1)\n",
    "\n",
    "if 'lda_topics' in features:\n",
    "    df.rename(columns={'brand':'Brand'}, inplace=True)\n",
    "\n",
    "    df['lda_topics'] = df['lda_topics'].map(eval)\n",
    "    # df['lda_topics'] = df['lda_topics'].map(key_of_max) # testing\n",
    "\n",
    "\n",
    "    normalized_info = pd.json_normalize(df['lda_topics'])\n",
    "    df = pd.concat([df.drop(columns=['lda_topics']), normalized_info], axis=1)\n",
    "\n",
    "    df.rename(columns={'brand':'lda_brand'}, inplace=True)\n",
    "    df.rename(columns={'Brand':'brand'}, inplace=True)\n",
    "\n",
    "df = pd.concat([df.drop(columns=[target]), df[target]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error # skip cell, needed for regressor\n",
    "\n",
    "df[target] = df[target].map(np.log)\n",
    "\n",
    "X = df.drop(columns=[target])  # features\n",
    "y = df.iloc[:,-1].values    # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # skip cell, needed for classifier\n",
    "\n",
    "df[target] = pd.cut(df[target], [0, 3, 6, 12, 24, 48, 120, 1000], labels=['0-3', '3-6', '6-12','12-24','24-48','48-120','120-1000'])\n",
    "# df[target] = pd.cut(df[target], [0, 48, 1000], labels=['0-48', '48-1000'])\n",
    "\n",
    "X = df.drop(columns=[target])  # features\n",
    "y = df.iloc[:,-1].values    # Target variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "x_categorical = X.select_dtypes(include=['object']).apply(label_encoder.fit_transform)\n",
    "x_numerical = X.select_dtypes(exclude=['object']).values\n",
    "x = pd.concat([pd.DataFrame(x_numerical), x_categorical], axis=1).values\n",
    "\n",
    "# Splitting the data\n",
    "x_train, x_test, y_train, y_test = train_test_split( \n",
    "          x, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest Regression to the dataset\n",
    "regressor = RandomForestRegressor(\n",
    "    criterion='squared_error',\n",
    "    min_samples_leaf=20,\n",
    "    n_estimators=50, \n",
    "    random_state=0, \n",
    "    oob_score=True\n",
    "    )\n",
    "# regressor = RandomForestClassifier(\n",
    "#     max_depth=25,\n",
    "#     min_samples_leaf=30, \n",
    "#     criterion='entropy', \n",
    "#     n_estimators=100, \n",
    "#     random_state=0, \n",
    "#     oob_score=True,\n",
    "#     )\n",
    "\n",
    "# Fit the regressor with x and y data\n",
    "regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Access the OOB Score\n",
    "oob_score = regressor.oob_score_\n",
    "print(f'Out-of-Bag Score: {oob_score}')\n",
    "\n",
    "# Making predictions\n",
    "predictions = regressor.predict(x_test)\n",
    "\n",
    "y_train_pred = regressor.predict(x_train)\n",
    "y_test_pred = regressor.predict(x_test)\n",
    "\n",
    "# Evaluating the model\n",
    "y_train_pred = [int(x) for x in y_train_pred] # needed for regressor\n",
    "y_test_pred = [int(x) for x in y_test_pred] # needed for regressor\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "print(\"Train Accuracy: %.1f%%\" %(train_accuracy * 100))\n",
    "print(\"Test Accuracy: %.1f%%\" %(test_accuracy * 100))\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions) # needed for regressor\n",
    "print(f'Mean Squared Error: {mse}') # needed for regressor\n",
    "\n",
    "r2 = r2_score(y_test, predictions) # needed for regressor\n",
    "print(f'R-squared: {r2}') # needed for regressor\n",
    "\n",
    "# takes a long time to compute\n",
    "# cross_value_score = cross_val_score(regressor, x_train, y_train)\n",
    "# print(f'cross_value_score: {cross_value_score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out-of-Bag Score: 0.28110463383846884 <br>\n",
    "Train Accuracy: 2.0% <br>\n",
    "Test Accuracy: 1.9% <br>\n",
    "Mean Squared Error: 2386.088419847645 <br>\n",
    "R-squared: 0.2734062099924697 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 trees\n",
    "### All papers\n",
    "Out-of-Bag Score: -0.010385546076016938 <br>\n",
    "Mean Squared Error: 2534.456497179695 <br>\n",
    "R-squared: 0.20268255231773014 <br>\n",
    "\n",
    "## 100 trees\n",
    "### All paper\n",
    "Out-of-Bag Score: 0.25749810100135195 <br>\n",
    "Train Accuracy: 6.1% <br>\n",
    "Test Accuracy: 1.8% <br>\n",
    "Mean Squared Error: 2331.636670402366 <br>\n",
    "R-squared: 0.26020977003388635 <br>\n",
    "cross_value_score: [0.2676171  0.26389397 0.25197756 0.27269653 0.27264813] <br>\n",
    "\n",
    "### All papers, regressor\n",
    "Out-of-Bag Score: 0.2943318712607208<br>\n",
    "Train Accuracy: 2.3%<br>\n",
    "Test Accuracy: 1.8%<br>\n",
    "Mean Squared Error: 2264.787157875292<br>\n",
    "R-squared: 0.2969975768644405<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # skip cell, Visualization\n",
    "\n",
    "X_grid = np.linspace(0,1000,1)\n",
    "X_grid = X_grid.reshape(len(X_grid),1) \n",
    "  \n",
    "plt.scatter(X,y, color='blue') #plotting real points\n",
    "plt.plot(X_grid, regressor.predict(X_grid),color='green') #plotting for predict points\n",
    "  \n",
    "plt.title(\"Random Forest Regression Results\")\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error # skip cell, Tree Visualization\n",
    "\n",
    "# Plot the decision tree\n",
    "def plotting_tree(tree):\n",
    "    # print(\"Worker thread running\")\n",
    "    n, tree_to_plot = tree\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plot_tree(tree_to_plot, feature_names=df.columns.tolist(), filled=True, rounded=True, fontsize=10)\n",
    "    plt.title(f\"Decision Tree {n} from Random Forest\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error # skip cell, Tree Visualization\n",
    "\n",
    "for tree in enumerate(regressor.estimators_):\n",
    "    plotting_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error # skip cell, Tree Visualization\n",
    "\n",
    "import concurrent.futures    \n",
    "\n",
    "pool = concurrent.futures.ThreadPoolExecutor(max_workers=10)\n",
    "\n",
    "for tree in enumerate(regressor.estimators_):\n",
    "    pool.submit(plotting_tree, tree)\n",
    "\n",
    "print('All trees submitted')\n",
    "\n",
    "pool.shutdown(wait=True)\n",
    "\n",
    "print(\"Main thread continuing to run\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
